{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "def speaker_diarization(\n",
    "            audio_file:str, \n",
    "            output_rttm_file_path:str,\n",
    "            output_csv_file_path:str):\n",
    "    \n",
    "    diarization_pipeline = Pipeline.from_pretrained(\n",
    "        \"pyannote/speaker-diarization-3.1\",\n",
    "        use_auth_token=\"hf_token\" # Hugging Face 토큰 입력\n",
    "    )\n",
    "\n",
    "    # CUDA 사용 설정\n",
    "    if torch.cuda.is_available():\n",
    "        diarization_pipeline.to(torch.device(\"cuda\"))\n",
    "\n",
    "    diarization_result = diarization_pipeline(audio_file)\n",
    "\n",
    "    with open(output_rttm_file_path, \"w\", encoding=\"utf-8\") as rttm_file:\n",
    "        diarization_result.write_rttm(rttm_file)\n",
    "\n",
    "    df_rttm =pd.read_csv(\n",
    "        output_rttm_file_path, # rttm 파일을 DataFrame으로 로드\n",
    "        sep=\" \",\n",
    "        names=[\n",
    "            \"Type\", \"File ID\", \"Channel ID\", \"start_time\", \n",
    "            \"Duration\", \"NA1\", \"NA2\", \"Speaker ID\", \"NA3\", \"NA4\"\n",
    "        ])\n",
    "\n",
    "    df_rttm[\"end_time\"] = df_rttm[\"start_time\"] + df_rttm[\"Duration\"]\n",
    "\n",
    "    # speaker ID를 기준으로 화자별 구간 나누기\n",
    "    df_rttm[\"number\"] = None\n",
    "    df_rttm.at[0, \"number\"] = 0\n",
    "\n",
    "    for i in range(1, len(df_rttm)):\n",
    "        if df_rttm.at[i, \"Speaker ID\"] != df_rttm.at[i-1, \"Speaker ID\"]:\n",
    "            df_rttm.at[i, \"number\"] = df_rttm.at[i-1, \"number\"] + 1\n",
    "        else:\n",
    "            df_rttm.at[i, \"number\"] = df_rttm.at[i-1, \"number\"]\n",
    "    \n",
    "    df_rttm_grouped = df_rttm.groupby(\"number\").agg(\n",
    "        start=pd.NamedAgg(column=\"start_time\", aggfunc=\"min\"),\n",
    "        end=pd.NamedAgg(column=\"end_time\", aggfunc=\"max\"),\n",
    "        speaker_id=pd.NamedAgg(column=\"Speaker ID\", aggfunc=\"first\")\n",
    "    )\n",
    "\n",
    "    df_rttm_grouped[\"duration\"] = df_rttm_grouped[\"end\"] - df_rttm_grouped[\"start\"]\n",
    "\n",
    "    df_rttm_grouped.to_csv(output_csv_file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    return df_rttm_grouped\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    audio_file = \"./CH/chapter5/data/multi_speaker_audio_2023_1min.wav\"\n",
    "    output_rttm_file_path = \"./CH/chapter5/data/diarization_output.rttm\"\n",
    "    output_csv_file_path = \"./CH/chapter5/data/diarization_output.csv\"\n",
    "\n",
    "    diarization_result = speaker_diarization(\n",
    "        audio_file,\n",
    "        output_rttm_file_path,\n",
    "        output_csv_file_path\n",
    "    )\n",
    "\n",
    "    print(diarization_result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
